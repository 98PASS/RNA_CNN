{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "alien-testing",
   "metadata": {},
   "source": [
    "#### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "musical-receipt",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Redes neurais, funções de ativação, otimizadores e tensores\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "# Dados, Conjuntos e Transformações\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "import torchvision.transforms as transforms\n",
    "import string # para a construção de um dicionário essencial ao sistema\n",
    "# io do Sistema Operacional (para ler base de dados)\n",
    "import os\n",
    "from os import walk\n",
    "# Manipulação Gráfica (para plotar imagens e gráficos) e randomizações\n",
    "from skimage import transform # função para modificar facilmente o tamanho de uma imagem\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import random\n",
    "from datetime import datetime\n",
    "import math"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "alert-alarm",
   "metadata": {},
   "source": [
    "###### Setup do Estado de Execução"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "powerful-portsmouth",
   "metadata": {},
   "outputs": [],
   "source": [
    "# semente de random\n",
    "np.random.seed(random.seed(datetime.now()))\n",
    "\n",
    "# dispositivo de calculo\n",
    "dispositivo = 'cuda' if torch.cuda.is_available() else 'cpu'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "alive-tracker",
   "metadata": {},
   "source": [
    "#### Classe Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "amended-station",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DatasetMassey(Dataset):\n",
    "    def __init__(self,raiz='Massey/handgestures_combinado/', transform=None):\n",
    "        #construtor da superclasse\n",
    "        super(DatasetMassey, self).__init__()\n",
    "        #ler dados\n",
    "        self.x = []\n",
    "        self.y = []\n",
    "        self.transform = transform\n",
    "        self.raiz = raiz\n",
    "        # loops para leitura de dados e preenchimento de X(dado) e Y(label)\n",
    "        for (_, _, filenames) in walk(raiz):\n",
    "            self.x.extend(sorted(filenames)) # adiciona o nome de arquivo a X\n",
    "            break\n",
    "        # para cada exemplo de X, pegue a label e armazene no dataset\n",
    "        for exemplo in self.x:\n",
    "            self.y.extend(exemplo[6])\n",
    "        \n",
    "        #armazene o tamanho do dataset\n",
    "        self.n_amostras = len(self.x)\n",
    "        self.n_classes = np.unique(self.y)\n",
    "        \n",
    "    def __getitem__(self, indice):\n",
    "        # Só aqui no GetItem, as imagens serão lidas de fato\n",
    "        # Isso ajuda na eficiência de memória e tempo, pois só lemos e carregamos do disco ao precisarmos delas\n",
    "        \n",
    "        caminho_de_arquivo = os.path.join(self.raiz, self.x[indice])\n",
    "        amostra = {'imagem':plt.imread(caminho_de_arquivo),'label':self.y[indice]}\n",
    "        \n",
    "        if self.transform:\n",
    "            amostra = self.transform(amostra)\n",
    "        \n",
    "        return amostra\n",
    "    \n",
    "    def __len__(self):\n",
    "        return self.n_amostras\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "vocal-value",
   "metadata": {},
   "source": [
    "#### Dataloaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "assured-message",
   "metadata": {},
   "outputs": [],
   "source": [
    "def CriarDataloaders(dataset=None, tamanho_batch=4, bagunçar=True, porcentagem_split=.2):\n",
    "    \n",
    "    if dataset is not None:   \n",
    "        dataset = dataset\n",
    "        indices = list(range(len(dataset)))\n",
    "        split = int(np.floor(porcentagem_split * len(dataset)))\n",
    "\n",
    "        if bagunçar :            \n",
    "            # MISTURA OS INDICES\n",
    "            np.random.shuffle(indices)\n",
    "\n",
    "        indices_treino, indices_validação = indices[split:], indices[:split]\n",
    "\n",
    "        sampler_treino = SubsetRandomSampler(indices_treino)\n",
    "        sampler_validação = SubsetRandomSampler(indices_validação)\n",
    "\n",
    "        loader_treino = torch.utils.data.DataLoader(dataset, batch_size=tamanho_batch, sampler=sampler_treino)\n",
    "        loader_validação = torch.utils.data.DataLoader(dataset,batch_size=tamanho_batch, sampler=sampler_validação)\n",
    "\n",
    "        return loader_treino, loader_validação\n",
    "    else:\n",
    "        print(\"Sem dataset = sem dados, sem dados = sem dataloaders\")\n",
    "        return None,None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "strong-trout",
   "metadata": {},
   "source": [
    "#### Transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "controversial-manor",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MinhaRescale(object):\n",
    "    def __init__(self, output_size):\n",
    "        assert isinstance(output_size, (int, tuple))\n",
    "        self.output_size = output_size\n",
    "   \n",
    "    def __call__(self, amostra):\n",
    "        imagem, label = amostra['imagem'], amostra['label']\n",
    "        h, w = imagem.shape[:2]\n",
    "        \n",
    "        new_h, new_w = self.output_size\n",
    "        new_h, new_w = int(new_h), int(new_w)\n",
    "        img = transform.resize(imagem, (new_h, new_w))\n",
    "        label = label\n",
    "        return {'imagem': img, 'label': label}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "liable-manitoba",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ToTensor(object):\n",
    "    def __init__(self):\n",
    "        # Cria uma lista com os caracteres em lowercase\n",
    "        letras = list(string.ascii_lowercase)\n",
    "        \n",
    "        # Cria uma lista com os dígitos numéricos decimais\n",
    "        numeros = list(string.digits)\n",
    "        \n",
    "        # Cria a lista unida de Dígitos e Letras (Que é todo o nosso conjunto de labels do Massey)\n",
    "        A_Grande_Lista = numeros+letras\n",
    "        \n",
    "        # Cria um dicionário vazio que será preenchido, mapeando Label -> índice numérico\n",
    "        self.O_Grande_Dicionario = dict()\n",
    "        \n",
    "#         print(A_Grande_Lista)\n",
    "\n",
    "        # Preenche o dicionário, mapeando cada item da lista de labels para um índice numérico\n",
    "        for i in range(len(A_Grande_Lista)):\n",
    "            self.O_Grande_Dicionario[A_Grande_Lista[i]] = i\n",
    "            if(i>=len(numeros)):\n",
    "                self.O_Grande_Dicionario[i] = A_Grande_Lista[i]\n",
    "        \n",
    "#         print(self.O_Grande_Dicionario)\n",
    "        \n",
    "    def __call__(self, amostra):\n",
    "        imagem, label = amostra['imagem'], amostra['label']\n",
    "        # Sobre a Label\n",
    "            # Devemos trocar a String por seu índice numérico no dicionário\n",
    "            # Com o índice numérico podemos transformar em um torch.Tensor\n",
    "        label = self.O_Grande_Dicionario[label]\n",
    "        label = torch.tensor(label)\n",
    "        \n",
    "        # Sobre a Imagem\n",
    "            # Devemos Trocar os eixos pois:\n",
    "            # imagem numpy: H x W x Canais\n",
    "            # imagem torch: Canais X H X W\n",
    "        imagem = imagem.transpose((2, 0, 1))\n",
    "        \n",
    "        # Retorno da Tupla de Tensores\n",
    "        return {'imagem': torch.from_numpy(imagem),\n",
    "                'label': label}\n",
    "    \n",
    "    # Função que retorna O Grande Dicionario\n",
    "    def getDicionario(self):\n",
    "        return self.O_Grande_Dicionario\n",
    "    \n",
    "    # Função que converte label de volta para String\n",
    "        # Só serve pra verificar se tá tudo OK\n",
    "    def TensorString(self, tensor):\n",
    "        item = tensor.item()\n",
    "        if( item > 9):\n",
    "            return self.O_Grande_Dicionario[item]\n",
    "        else:\n",
    "            return str(item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "painted-herald",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Esta só serve para transformar imagens TorchTensor em Imagens do Numpy\n",
    "class ToNumpyImage(object):\n",
    "    def __call__(self, tensor_imagem):\n",
    "        imagem = tensor_imagem.permute(1, 2, 0)\n",
    "        return imagem"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "opponent-satisfaction",
   "metadata": {},
   "source": [
    "#### Funções de Treino e Validação"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "challenging-rocket",
   "metadata": {},
   "outputs": [],
   "source": [
    "def treinar(loader_treino, modelo, n_epocas, fun_custo, otimizador,dispositivo,nome_modelo=\"não passado\",nome_otimizador=\"não passado\",indice_execução=0):\n",
    "    print(\"Iniciado o Treinamento Número [ \"+str(indice_execução)+ \" ] - Modelo:\",nome_modelo,\" Com Otimizador:\",nome_otimizador)\n",
    "    modelo = modelo.to(dispositivo)\n",
    "    modelo.train()\n",
    "    \n",
    "    n_passos = len(loader_treino)\n",
    "    for epoca in range(n_epocas):\n",
    "        for passo, amostra in enumerate(loader_treino):\n",
    "            imagens = amostra['imagem'].to(dispositivo)\n",
    "            labels = amostra['label'].to(dispositivo)\n",
    "\n",
    "            saidas = modelo(imagens)\n",
    "            custo = fun_custo(saidas,labels)\n",
    "\n",
    "            custo.backward()\n",
    "            otimizador.step()\n",
    "            otimizador.zero_grad()\n",
    "        \n",
    "        print(f'Época [ {epoca+1} / {n_epocas} ]\\t|\\tCusto [ {custo} ]')\n",
    "    print(\"Finalizado o Treinamento do Modelo\")\n",
    "    return modelo, fun_custo, otimizador"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "periodic-texas",
   "metadata": {},
   "outputs": [],
   "source": [
    "def validar(loader_validação, modelo, dispositivo):\n",
    "    modelo.to(dispositivo)\n",
    "    modelo.eval()\n",
    "    n_corretos = 0\n",
    "    n_amostras = 0\n",
    "    with torch.no_grad():\n",
    "        for exemplos in (loader_validação):\n",
    "            imagens = exemplos['imagem'].to(dispositivo)\n",
    "            labels = exemplos['label'].to(dispositivo)\n",
    "\n",
    "            saidas = modelo(imagens)\n",
    "            _, predição = torch.max(saidas,1)\n",
    "            n_amostras += labels.size(0)\n",
    "            n_corretos += (predição == labels).sum().item()\n",
    "    precisão = 100.0 * n_corretos / n_amostras\n",
    "    return precisão"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "silver-interface",
   "metadata": {},
   "outputs": [],
   "source": [
    "def armazenar_media_desvio(lista_precisões,nome_modelo,nome_otimizador):\n",
    "    precisão_media = sum(lista_precisões)/len(lista_precisões)\n",
    "    #somatorio: raiz_quadrada((xi - x_media)²) / N\n",
    "    desvio_padrao = 0.0\n",
    "    for precisão in lista_precisões: desvio_padrao += math.sqrt(pow((precisão-precisão_media)/len(lista_precisões),2))\n",
    "    # Armazena as informações\n",
    "    informações = \"Precisão Média = \"+str(precisão_media)+\", Desvio Padrão da Precisão = \"+str(desvio_padrao)\n",
    "    guardar_report(report=informações,modelo=nome_modelo,otimizador=nome_otimizador)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dressed-europe",
   "metadata": {},
   "source": [
    "#### CNN 1 - Arquitetura Lenet (Com Entrada RGB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "organizational-artist",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Lenet_RGB(nn.Module):\n",
    "    def __init__(self, n_classes):\n",
    "        super(Lenet_RGB,self).__init__()\n",
    "        \n",
    "        # Armazena numero de classes do problema\n",
    "        self.n_classes = n_classes\n",
    "        \n",
    "        # Função de Pool que será usada na Rede -> Kernel_Size = 2 , Stride = 2\n",
    "        self.pool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        \n",
    "        # Primeira camada\n",
    "        self.conv1 = nn.Conv2d(in_channels= 3, out_channels= 6, kernel_size=5)\n",
    "            \n",
    "        # Segunda camada\n",
    "        self.conv2 = nn.Conv2d(in_channels= 6, out_channels= 16, kernel_size=5)\n",
    "        \n",
    "        # Treceira camada\n",
    "        self.conv3 = nn.Conv2d(in_channels= 16, out_channels= 120 , kernel_size=5)\n",
    "        \n",
    "        # Primeira camada FC\n",
    "        self.fc1 = nn.Linear(in_features= 120, out_features= 84)\n",
    "        \n",
    "        # Segunda camada FC\n",
    "        self.fc2 = nn.Linear(in_features=84, out_features= self.n_classes)\n",
    "        \n",
    "    def forward(self,entrada):\n",
    "        \n",
    "        saida = self.conv1(entrada)\n",
    "        saida = F.relu(saida)\n",
    "        saida = self.pool(saida)\n",
    "        \n",
    "        saida = self.conv2(saida)\n",
    "        saida = F.relu(saida)\n",
    "        saida = self.pool(saida)\n",
    "        \n",
    "        saida = self.conv3(saida)\n",
    "        saida = F.relu(saida)\n",
    "        \n",
    "        saida = saida.view(-1,120)\n",
    "        \n",
    "        saida = self.fc1(saida)\n",
    "        saida = F.relu(saida)\n",
    "        \n",
    "        saida = self.fc2(saida)\n",
    "        \n",
    "        return saida"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "forbidden-playlist",
   "metadata": {},
   "source": [
    "#### CNN 2 - Lenet Modificada (Quantidade de Canais de Saída das Camadas Convolucionais Aumentada)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "instructional-acrylic",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Lenet_RGB_Mod(nn.Module):\n",
    "    def __init__(self, n_classes):\n",
    "        super(Lenet_RGB_Mod,self).__init__()\n",
    "        \n",
    "        # Armazena numero de classes do problema\n",
    "        self.n_classes = n_classes\n",
    "        \n",
    "        # Função de Pool que será usada na Rede -> Kernel_Size = 2 , Stride = 2\n",
    "        self.pool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        \n",
    "        # Primeira camada\n",
    "        self.conv1 = nn.Conv2d(in_channels= 3, out_channels= 18, kernel_size=5)\n",
    "            \n",
    "        # Segunda camada\n",
    "        self.conv2 = nn.Conv2d(in_channels= 18, out_channels= 32, kernel_size=5)\n",
    "        \n",
    "        # Treceira camada\n",
    "        self.conv3 = nn.Conv2d(in_channels= 32, out_channels= 160 , kernel_size=5)\n",
    "        \n",
    "        # Primeira camada FC\n",
    "        self.fc1 = nn.Linear(in_features= 160, out_features= 84)\n",
    "        \n",
    "        # Segunda camada FC\n",
    "        self.fc2 = nn.Linear(in_features=84, out_features= self.n_classes)\n",
    "        \n",
    "    def forward(self,entrada):\n",
    "        \n",
    "        saida = self.conv1(entrada)\n",
    "        saida = F.relu(saida)\n",
    "        saida = self.pool(saida)\n",
    "        \n",
    "        saida = self.conv2(saida)\n",
    "        saida = F.relu(saida)\n",
    "        saida = self.pool(saida)\n",
    "        \n",
    "        saida = self.conv3(saida)\n",
    "        saida = F.relu(saida)\n",
    "        \n",
    "        saida = saida.view(-1,160)\n",
    "        \n",
    "        saida = self.fc1(saida)\n",
    "        saida = F.relu(saida)\n",
    "        \n",
    "        saida = self.fc2(saida)\n",
    "        \n",
    "        return saida"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "floppy-brick",
   "metadata": {},
   "source": [
    "#### CNN 3 - MiniVgg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "above-cuisine",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MiniVgg(nn.Module):\n",
    "    def __init__(self, n_classes): \n",
    "        super(MiniVgg, self).__init__()\n",
    "        \n",
    "        # Maxpool usada\n",
    "        self.pool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        \n",
    "        # Camadas convolucionais com normalização de batch\n",
    "        self.conv1 = nn.Conv2d(in_channels=3, out_channels=64, kernel_size=3, padding = 1)\n",
    "        self.norm1 = nn.BatchNorm2d(64)\n",
    "        \n",
    "        self.conv2 = nn.Conv2d(64, 64, 3, padding = 1)\n",
    "        self.norm2 = nn.BatchNorm2d(64)\n",
    "               \n",
    "        self.conv3 = nn.Conv2d(64, 128, 3, padding = 1)\n",
    "        self.norm3 = nn.BatchNorm2d(128)\n",
    "        \n",
    "        self.conv4 = nn.Conv2d(128, 128, 3, padding = 1)\n",
    "        self.norm4 = nn.BatchNorm2d(128)\n",
    "        \n",
    "        self.conv5 = nn.Conv2d(128, 256, 3, padding = 1)\n",
    "        self.norm5 = nn.BatchNorm2d(256)\n",
    "        \n",
    "        self.conv6 = nn.Conv2d(256, 256, 3, padding = 1)\n",
    "        self.norm6 = nn.BatchNorm2d(256)\n",
    "\n",
    "        self.conv7 = nn.Conv2d(256, 512, 3, padding = 1)\n",
    "        self.norm7 = nn.BatchNorm2d(512)\n",
    "        \n",
    "        self.conv8 = nn.Conv2d(512, 512, 3, padding = 1)\n",
    "        self.norm8 = nn.BatchNorm2d(512)\n",
    "        \n",
    "        # Camada totalmente conectada com normalização de batch\n",
    "        self.fc1 = nn.Linear(512 * 4 * 4, 128)\n",
    "        self.norm9 = nn.BatchNorm1d(128)\n",
    "       \n",
    "        self.fc2 = nn.Linear(128, 64)\n",
    "        self.norm10 = nn.BatchNorm1d(64)\n",
    "        \n",
    "        self.fc3 = nn.Linear(64, n_classes)\n",
    "        \n",
    "\n",
    "    def forward(self, x):       \n",
    "        \n",
    "        saida = F.elu(self.norm1(self.conv1(x)))\n",
    "        saida = F.elu(self.norm2(self.conv2(saida)))\n",
    "        saida = self.pool(saida)\n",
    "        \n",
    "        saida = F.elu(self.norm3(self.conv3(saida)))\n",
    "        saida = F.elu(self.norm4(self.conv4(saida)))\n",
    "        saida = self.pool(saida)\n",
    "        \n",
    "        saida = F.elu(self.norm5(self.conv5(saida)))\n",
    "        saida = F.elu(self.norm6(self.conv6(saida)))\n",
    "        saida = self.pool(saida)\n",
    "        \n",
    "        saida = F.elu(self.norm7(self.conv7(saida)))\n",
    "        saida = F.elu(self.norm8(self.conv8(saida)))\n",
    "        \n",
    "        saida = saida.view(-1, 512 * 4 * 4)\n",
    "        \n",
    "        saida = F.elu(self.norm9(self.fc1(saida)))\n",
    "        saida = F.elu(self.norm10(self.fc2(saida)))\n",
    "        saida = self.fc3(saida)\n",
    "\n",
    "        return saida"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "knowing-highway",
   "metadata": {},
   "source": [
    "###### Classe Para Reduzir Código (retorna novas instancias de otimizadores e taxas de aprendizado diferentes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "registered-construction",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Getter_Parametro():\n",
    "    def __init__(self):\n",
    "        self.nomes_fun_custo = ['Entropia Cruzada','Erro Quadrático Médio','Logaritmo Negativo']\n",
    "        self.funções_de_custo = {'Entropia Cruzada':nn.CrossEntropyLoss,'Erro Quadrático Médio':nn.MSELoss,'Logaritmo Negativo':nn.BCELoss}\n",
    "        \n",
    "        self.nomes_otimizador = ['Gradiente Descendente','Adagrad','Adam']\n",
    "        self.otimizadores = {'Gradiente Descendente':torch.optim.SGD,'Adagrad':torch.optim.Adagrad,'Adam':torch.optim.Adam}\n",
    "        \n",
    "        self.taxas_aprendizado = [0.5,0.1,0.05,0.001]\n",
    "        self.indice_taxa =0\n",
    "\n",
    "    def get_otimizador(self,indice=0,quero_o_nome=False):\n",
    "        if quero_o_nome:\n",
    "            return self.nomes_otimizador[indice]\n",
    "        else:\n",
    "            return self.otimizadores[self.nomes_otimizador[indice]]\n",
    "        \n",
    "    def get_fun_custo(self,indice=0, quero_o_nome=False):\n",
    "        if quero_o_nome:\n",
    "            return self.nomes_fun_custo[indice]\n",
    "        else:\n",
    "            return self.funções_de_custo[self.nomes_fun_custo[indice]]()\n",
    "    \n",
    "    def get_lr(self):\n",
    "        taxa = self.taxas_aprendizado[self.indice_taxa]\n",
    "        self.indice_taxa += 1\n",
    "        self.indice_taxa %= len(self.taxas_aprendizado)\n",
    "        return taxa\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "continuing-guitar",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Função que armazena mais uma linha no arquivo de report\n",
    "def guardar_report(report,modelo,otimizador):\n",
    "    arquivo = open('resultados/report_Modelo-{}_Otimizador-{}'.format(modelo,otimizador),'a+')\n",
    "    arquivo.write('{}{}'.format(report,'\\n'))\n",
    "    arquivo.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "inappropriate-measure",
   "metadata": {},
   "source": [
    "---\n",
    "---\n",
    "# Execução\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "registered-convention",
   "metadata": {},
   "source": [
    "###### Insira Aqui o Número de Execuções e Épocas de Treinaento para cada treino Desejadas "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "expected-fifteen",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definindo a Transformação a ser utilizada\n",
    "composta = transforms.Compose([MinhaRescale((32,32)),ToTensor()])\n",
    "\n",
    "# Instanciando Novo DataSet\n",
    "ds_massey = DatasetMassey(raiz=\"Massey/handgestures_combinado/\",transform=composta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ideal-midnight",
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 20 #30\n",
    "épocas = 10 #10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "operating-provider",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iniciado o Treinamento Número [ 0 ] - Modelo: Lenet_RGB  Com Otimizador: Gradiente Descendente\n",
      "Época [ 1 / 10 ]\t|\tCusto [ 3.8008155822753906 ]\n",
      "Época [ 2 / 10 ]\t|\tCusto [ 3.462131977081299 ]\n",
      "Época [ 3 / 10 ]\t|\tCusto [ 3.539107322692871 ]\n",
      "Época [ 4 / 10 ]\t|\tCusto [ 3.517744779586792 ]\n",
      "Época [ 5 / 10 ]\t|\tCusto [ 3.5825397968292236 ]\n",
      "Época [ 6 / 10 ]\t|\tCusto [ 3.4797096252441406 ]\n",
      "Época [ 7 / 10 ]\t|\tCusto [ 3.6952545642852783 ]\n",
      "Época [ 8 / 10 ]\t|\tCusto [ 3.6278669834136963 ]\n",
      "Época [ 9 / 10 ]\t|\tCusto [ 3.5419371128082275 ]\n",
      "Época [ 10 / 10 ]\t|\tCusto [ 3.6056783199310303 ]\n",
      "Finalizado o Treinamento do Modelo\n",
      "Iniciado o Treinamento Número [ 1 ] - Modelo: Lenet_RGB  Com Otimizador: Gradiente Descendente\n",
      "Época [ 1 / 10 ]\t|\tCusto [ 3.8238067626953125 ]\n",
      "Época [ 2 / 10 ]\t|\tCusto [ 3.820324182510376 ]\n",
      "Época [ 3 / 10 ]\t|\tCusto [ 3.628328323364258 ]\n",
      "Época [ 4 / 10 ]\t|\tCusto [ 3.6903417110443115 ]\n",
      "Época [ 5 / 10 ]\t|\tCusto [ 3.563079357147217 ]\n",
      "Época [ 6 / 10 ]\t|\tCusto [ 3.505427837371826 ]\n",
      "Época [ 7 / 10 ]\t|\tCusto [ 3.5720980167388916 ]\n",
      "Época [ 8 / 10 ]\t|\tCusto [ 3.6952600479125977 ]\n",
      "Época [ 9 / 10 ]\t|\tCusto [ 3.654494047164917 ]\n",
      "Época [ 10 / 10 ]\t|\tCusto [ 3.7320961952209473 ]\n",
      "Finalizado o Treinamento do Modelo\n",
      "Iniciado o Treinamento Número [ 2 ] - Modelo: Lenet_RGB  Com Otimizador: Gradiente Descendente\n",
      "Época [ 1 / 10 ]\t|\tCusto [ 3.6902565956115723 ]\n",
      "Época [ 2 / 10 ]\t|\tCusto [ 3.6362056732177734 ]\n",
      "Época [ 3 / 10 ]\t|\tCusto [ 3.54831600189209 ]\n",
      "Época [ 4 / 10 ]\t|\tCusto [ 3.564337968826294 ]\n",
      "Época [ 5 / 10 ]\t|\tCusto [ 3.5413942337036133 ]\n",
      "Época [ 6 / 10 ]\t|\tCusto [ 3.6421079635620117 ]\n",
      "Época [ 7 / 10 ]\t|\tCusto [ 3.697089195251465 ]\n",
      "Época [ 8 / 10 ]\t|\tCusto [ 3.741330623626709 ]\n",
      "Época [ 9 / 10 ]\t|\tCusto [ 3.615017890930176 ]\n",
      "Época [ 10 / 10 ]\t|\tCusto [ 3.6612191200256348 ]\n",
      "Finalizado o Treinamento do Modelo\n",
      "Iniciado o Treinamento Número [ 3 ] - Modelo: Lenet_RGB  Com Otimizador: Gradiente Descendente\n",
      "Época [ 1 / 10 ]\t|\tCusto [ 3.722189426422119 ]\n",
      "Época [ 2 / 10 ]\t|\tCusto [ 3.8566782474517822 ]\n",
      "Época [ 3 / 10 ]\t|\tCusto [ 3.5652480125427246 ]\n",
      "Época [ 4 / 10 ]\t|\tCusto [ 3.719426155090332 ]\n",
      "Época [ 5 / 10 ]\t|\tCusto [ 3.753804922103882 ]\n",
      "Época [ 6 / 10 ]\t|\tCusto [ 3.640190601348877 ]\n",
      "Época [ 7 / 10 ]\t|\tCusto [ 3.3970518112182617 ]\n",
      "Época [ 8 / 10 ]\t|\tCusto [ 3.5136494636535645 ]\n",
      "Época [ 9 / 10 ]\t|\tCusto [ 3.5124881267547607 ]\n",
      "Época [ 10 / 10 ]\t|\tCusto [ 3.4881935119628906 ]\n",
      "Finalizado o Treinamento do Modelo\n",
      "Iniciado o Treinamento Número [ 4 ] - Modelo: Lenet_RGB  Com Otimizador: Gradiente Descendente\n",
      "Época [ 1 / 10 ]\t|\tCusto [ 3.4780433177948 ]\n",
      "Época [ 2 / 10 ]\t|\tCusto [ 3.4704251289367676 ]\n",
      "Época [ 3 / 10 ]\t|\tCusto [ 3.8118677139282227 ]\n",
      "Época [ 4 / 10 ]\t|\tCusto [ 3.662755012512207 ]\n",
      "Época [ 5 / 10 ]\t|\tCusto [ 3.5456318855285645 ]\n",
      "Época [ 6 / 10 ]\t|\tCusto [ 3.587676763534546 ]\n",
      "Época [ 7 / 10 ]\t|\tCusto [ 3.5038208961486816 ]\n",
      "Época [ 8 / 10 ]\t|\tCusto [ 3.6092746257781982 ]\n",
      "Época [ 9 / 10 ]\t|\tCusto [ 3.7251834869384766 ]\n",
      "Época [ 10 / 10 ]\t|\tCusto [ 3.635169744491577 ]\n",
      "Finalizado o Treinamento do Modelo\n",
      "Iniciado o Treinamento Número [ 5 ] - Modelo: Lenet_RGB  Com Otimizador: Gradiente Descendente\n",
      "Época [ 1 / 10 ]\t|\tCusto [ 3.6705222129821777 ]\n",
      "Época [ 2 / 10 ]\t|\tCusto [ 3.9072680473327637 ]\n",
      "Época [ 3 / 10 ]\t|\tCusto [ 3.6442158222198486 ]\n",
      "Época [ 4 / 10 ]\t|\tCusto [ 3.5859286785125732 ]\n",
      "Época [ 5 / 10 ]\t|\tCusto [ 3.665531873703003 ]\n",
      "Época [ 6 / 10 ]\t|\tCusto [ 3.70155668258667 ]\n",
      "Época [ 7 / 10 ]\t|\tCusto [ 3.609327554702759 ]\n",
      "Época [ 8 / 10 ]\t|\tCusto [ 3.4815175533294678 ]\n",
      "Época [ 9 / 10 ]\t|\tCusto [ 3.4595251083374023 ]\n",
      "Época [ 10 / 10 ]\t|\tCusto [ 3.6689648628234863 ]\n",
      "Finalizado o Treinamento do Modelo\n",
      "Iniciado o Treinamento Número [ 6 ] - Modelo: Lenet_RGB  Com Otimizador: Gradiente Descendente\n",
      "Época [ 1 / 10 ]\t|\tCusto [ 3.7473933696746826 ]\n",
      "Época [ 2 / 10 ]\t|\tCusto [ 3.8587090969085693 ]\n",
      "Época [ 3 / 10 ]\t|\tCusto [ 3.709752082824707 ]\n",
      "Época [ 4 / 10 ]\t|\tCusto [ 3.4130828380584717 ]\n",
      "Época [ 5 / 10 ]\t|\tCusto [ 3.601088762283325 ]\n",
      "Época [ 6 / 10 ]\t|\tCusto [ 3.5720739364624023 ]\n",
      "Época [ 7 / 10 ]\t|\tCusto [ 3.5754237174987793 ]\n",
      "Época [ 8 / 10 ]\t|\tCusto [ 3.4991776943206787 ]\n",
      "Época [ 9 / 10 ]\t|\tCusto [ 3.5313563346862793 ]\n",
      "Época [ 10 / 10 ]\t|\tCusto [ 3.7281620502471924 ]\n",
      "Finalizado o Treinamento do Modelo\n",
      "Iniciado o Treinamento Número [ 7 ] - Modelo: Lenet_RGB  Com Otimizador: Gradiente Descendente\n",
      "Época [ 1 / 10 ]\t|\tCusto [ 3.754551410675049 ]\n",
      "Época [ 2 / 10 ]\t|\tCusto [ 3.589275360107422 ]\n",
      "Época [ 3 / 10 ]\t|\tCusto [ 3.5696449279785156 ]\n",
      "Época [ 4 / 10 ]\t|\tCusto [ 3.611727714538574 ]\n",
      "Época [ 5 / 10 ]\t|\tCusto [ 3.6415505409240723 ]\n",
      "Época [ 6 / 10 ]\t|\tCusto [ 3.7501723766326904 ]\n",
      "Época [ 7 / 10 ]\t|\tCusto [ 3.7222180366516113 ]\n",
      "Época [ 8 / 10 ]\t|\tCusto [ 3.643444776535034 ]\n",
      "Época [ 9 / 10 ]\t|\tCusto [ 3.534213066101074 ]\n",
      "Época [ 10 / 10 ]\t|\tCusto [ 3.6469788551330566 ]\n",
      "Finalizado o Treinamento do Modelo\n",
      "Iniciado o Treinamento Número [ 8 ] - Modelo: Lenet_RGB  Com Otimizador: Gradiente Descendente\n",
      "Época [ 1 / 10 ]\t|\tCusto [ 3.42950177192688 ]\n",
      "Época [ 2 / 10 ]\t|\tCusto [ 3.575922966003418 ]\n",
      "Época [ 3 / 10 ]\t|\tCusto [ 3.6328701972961426 ]\n",
      "Época [ 4 / 10 ]\t|\tCusto [ 3.6793417930603027 ]\n",
      "Época [ 5 / 10 ]\t|\tCusto [ 3.648630142211914 ]\n",
      "Época [ 6 / 10 ]\t|\tCusto [ 3.559237480163574 ]\n",
      "Época [ 7 / 10 ]\t|\tCusto [ 3.55938458442688 ]\n",
      "Época [ 8 / 10 ]\t|\tCusto [ 3.593308925628662 ]\n",
      "Época [ 9 / 10 ]\t|\tCusto [ 3.6275529861450195 ]\n",
      "Época [ 10 / 10 ]\t|\tCusto [ 3.4438066482543945 ]\n",
      "Finalizado o Treinamento do Modelo\n",
      "Iniciado o Treinamento Número [ 9 ] - Modelo: Lenet_RGB  Com Otimizador: Gradiente Descendente\n",
      "Época [ 1 / 10 ]\t|\tCusto [ 3.675098419189453 ]\n",
      "Época [ 2 / 10 ]\t|\tCusto [ 3.511850357055664 ]\n",
      "Época [ 3 / 10 ]\t|\tCusto [ 3.5831990242004395 ]\n",
      "Época [ 4 / 10 ]\t|\tCusto [ 3.7519166469573975 ]\n",
      "Época [ 5 / 10 ]\t|\tCusto [ 3.62166428565979 ]\n",
      "Época [ 6 / 10 ]\t|\tCusto [ 3.7707324028015137 ]\n",
      "Época [ 7 / 10 ]\t|\tCusto [ 3.84122633934021 ]\n",
      "Época [ 8 / 10 ]\t|\tCusto [ 3.6722986698150635 ]\n",
      "Época [ 9 / 10 ]\t|\tCusto [ 3.57389497756958 ]\n",
      "Época [ 10 / 10 ]\t|\tCusto [ 3.565898895263672 ]\n",
      "Finalizado o Treinamento do Modelo\n",
      "Iniciado o Treinamento Número [ 10 ] - Modelo: Lenet_RGB  Com Otimizador: Gradiente Descendente\n",
      "Época [ 1 / 10 ]\t|\tCusto [ 3.7344346046447754 ]\n",
      "Época [ 2 / 10 ]\t|\tCusto [ 3.5693891048431396 ]\n",
      "Época [ 3 / 10 ]\t|\tCusto [ 3.492957353591919 ]\n",
      "Época [ 4 / 10 ]\t|\tCusto [ 3.6214733123779297 ]\n",
      "Época [ 5 / 10 ]\t|\tCusto [ 3.6356654167175293 ]\n",
      "Época [ 6 / 10 ]\t|\tCusto [ 3.588334798812866 ]\n",
      "Época [ 7 / 10 ]\t|\tCusto [ 3.496854782104492 ]\n",
      "Época [ 8 / 10 ]\t|\tCusto [ 3.6918606758117676 ]\n",
      "Época [ 9 / 10 ]\t|\tCusto [ 3.580146312713623 ]\n",
      "Época [ 10 / 10 ]\t|\tCusto [ 3.514779567718506 ]\n",
      "Finalizado o Treinamento do Modelo\n",
      "Iniciado o Treinamento Número [ 11 ] - Modelo: Lenet_RGB  Com Otimizador: Gradiente Descendente\n",
      "Época [ 1 / 10 ]\t|\tCusto [ 3.779175281524658 ]\n",
      "Época [ 2 / 10 ]\t|\tCusto [ 3.666670083999634 ]\n",
      "Época [ 3 / 10 ]\t|\tCusto [ 3.6006240844726562 ]\n",
      "Época [ 4 / 10 ]\t|\tCusto [ 3.618163585662842 ]\n",
      "Época [ 5 / 10 ]\t|\tCusto [ 3.9559051990509033 ]\n",
      "Época [ 6 / 10 ]\t|\tCusto [ 3.5837578773498535 ]\n",
      "Época [ 7 / 10 ]\t|\tCusto [ 3.5489249229431152 ]\n",
      "Época [ 8 / 10 ]\t|\tCusto [ 3.6666016578674316 ]\n",
      "Época [ 9 / 10 ]\t|\tCusto [ 3.6306047439575195 ]\n",
      "Época [ 10 / 10 ]\t|\tCusto [ 3.504701852798462 ]\n",
      "Finalizado o Treinamento do Modelo\n",
      "Iniciado o Treinamento Número [ 12 ] - Modelo: Lenet_RGB  Com Otimizador: Gradiente Descendente\n",
      "Época [ 1 / 10 ]\t|\tCusto [ 3.7058959007263184 ]\n",
      "Época [ 2 / 10 ]\t|\tCusto [ 3.809475898742676 ]\n",
      "Época [ 3 / 10 ]\t|\tCusto [ 3.483645439147949 ]\n",
      "Época [ 4 / 10 ]\t|\tCusto [ 3.5763206481933594 ]\n",
      "Época [ 5 / 10 ]\t|\tCusto [ 3.5208687782287598 ]\n",
      "Época [ 6 / 10 ]\t|\tCusto [ 3.7626616954803467 ]\n",
      "Época [ 7 / 10 ]\t|\tCusto [ 3.6544742584228516 ]\n",
      "Época [ 8 / 10 ]\t|\tCusto [ 3.5823252201080322 ]\n",
      "Época [ 9 / 10 ]\t|\tCusto [ 3.4611077308654785 ]\n",
      "Época [ 10 / 10 ]\t|\tCusto [ 3.732994556427002 ]\n",
      "Finalizado o Treinamento do Modelo\n",
      "Iniciado o Treinamento Número [ 13 ] - Modelo: Lenet_RGB  Com Otimizador: Gradiente Descendente\n",
      "Época [ 1 / 10 ]\t|\tCusto [ 3.638214349746704 ]\n",
      "Época [ 2 / 10 ]\t|\tCusto [ 3.523749828338623 ]\n",
      "Época [ 3 / 10 ]\t|\tCusto [ 3.6861467361450195 ]\n",
      "Época [ 4 / 10 ]\t|\tCusto [ 3.5829758644104004 ]\n",
      "Época [ 5 / 10 ]\t|\tCusto [ 3.343468427658081 ]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Época [ 6 / 10 ]\t|\tCusto [ 3.603614330291748 ]\n",
      "Época [ 7 / 10 ]\t|\tCusto [ 3.649087429046631 ]\n",
      "Época [ 8 / 10 ]\t|\tCusto [ 3.758765459060669 ]\n",
      "Época [ 9 / 10 ]\t|\tCusto [ 3.462859630584717 ]\n",
      "Época [ 10 / 10 ]\t|\tCusto [ 3.7035813331604004 ]\n",
      "Finalizado o Treinamento do Modelo\n",
      "Iniciado o Treinamento Número [ 14 ] - Modelo: Lenet_RGB  Com Otimizador: Gradiente Descendente\n",
      "Época [ 1 / 10 ]\t|\tCusto [ 3.716265916824341 ]\n",
      "Época [ 2 / 10 ]\t|\tCusto [ 3.495204448699951 ]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-18-743284611d2a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m                 \u001b[0;31m# Treine o modelo instanciado com os seus parâmetros (n epocas, otimizador, loader de treino)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 32\u001b[0;31m                 \u001b[0mmodelo_instanciado\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtreinar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloader_treino\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmodelo_instanciado\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mépocas\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mfun_custo\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0motimizador\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdispositivo\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmodelo\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mgp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_otimizador\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindice_otimizador\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mexecução\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     33\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m                 \u001b[0;31m####### CÓDIGO PARA VALIDAÇÃO #######\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-8-8169d0ad975e>\u001b[0m in \u001b[0;36mtreinar\u001b[0;34m(loader_treino, modelo, n_epocas, fun_custo, otimizador, dispositivo, nome_modelo, nome_otimizador, indice_execução)\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mn_passos\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloader_treino\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mepoca\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_epocas\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mpasso\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mamostra\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloader_treino\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m             \u001b[0mimagens\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mamostra\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'imagem'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdispositivo\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m             \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mamostra\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'label'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdispositivo\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    433\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sampler_iter\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    434\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 435\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    436\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    437\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    473\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    474\u001b[0m         \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 475\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_fetcher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    476\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    477\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36mfetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     42\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauto_collation\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     42\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauto_collation\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-3-f1fe15b7a2f9>\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, indice)\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 30\u001b[0;31m             \u001b[0mamostra\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mamostra\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     31\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mamostra\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/torchvision/transforms/transforms.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, img)\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransforms\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 67\u001b[0;31m             \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     68\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-5-4380f62958ed>\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, amostra)\u001b[0m\n\u001b[1;32m     10\u001b[0m         \u001b[0mnew_h\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnew_w\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput_size\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m         \u001b[0mnew_h\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnew_w\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_h\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_w\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m         \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtransform\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimagem\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mnew_h\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnew_w\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m         \u001b[0mlabel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m'imagem'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'label'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/skimage/transform/_warps.py\u001b[0m in \u001b[0;36mresize\u001b[0;34m(image, output_shape, order, mode, cval, clip, preserve_range, anti_aliasing, anti_aliasing_sigma)\u001b[0m\n\u001b[1;32m    145\u001b[0m                              \"documentation of numpy.pad for more info.\")\n\u001b[1;32m    146\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 147\u001b[0;31m         image = ndi.gaussian_filter(image, anti_aliasing_sigma,\n\u001b[0m\u001b[1;32m    148\u001b[0m                                     cval=cval, mode=ndi_mode)\n\u001b[1;32m    149\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/scipy/ndimage/filters.py\u001b[0m in \u001b[0;36mgaussian_filter\u001b[0;34m(input, sigma, order, output, mode, cval, truncate)\u001b[0m\n\u001b[1;32m    296\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxes\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    297\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msigma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m \u001b[0;32min\u001b[0m \u001b[0maxes\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 298\u001b[0;31m             gaussian_filter1d(input, sigma, axis, order, output,\n\u001b[0m\u001b[1;32m    299\u001b[0m                               mode, cval, truncate)\n\u001b[1;32m    300\u001b[0m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/scipy/ndimage/filters.py\u001b[0m in \u001b[0;36mgaussian_filter1d\u001b[0;34m(input, sigma, axis, order, output, mode, cval, truncate)\u001b[0m\n\u001b[1;32m    215\u001b[0m     \u001b[0;31m# Since we are calling correlate, not convolve, revert the kernel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    216\u001b[0m     \u001b[0mweights\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_gaussian_kernel1d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msigma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 217\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mcorrelate1d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweights\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcval\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    218\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    219\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/scipy/ndimage/filters.py\u001b[0m in \u001b[0;36mcorrelate1d\u001b[0;34m(input, weights, axis, output, mode, cval, origin)\u001b[0m\n\u001b[1;32m     92\u001b[0m                          '(len(weights)-1) // 2')\n\u001b[1;32m     93\u001b[0m     \u001b[0mmode\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_ni_support\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_extend_mode_to_code\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 94\u001b[0;31m     _nd_image.correlate1d(input, weights, axis, output, mode, cval,\n\u001b[0m\u001b[1;32m     95\u001b[0m                           origin)\n\u001b[1;32m     96\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "gp = Getter_Parametro()\n",
    "modelos = {'Lenet_RGB':Lenet_RGB,'Lenet_RGB_MODIFICADA':Lenet_RGB_Mod,'MiniVgg':MiniVgg}\n",
    "\n",
    "# Para cada modelo na lista de classes de modelo, execute N vezes o treino e validação variando: Taxas de Aprendizado e Otimizadores\n",
    "for taxa_aprendizado in [0.5,0.1,0.05,0.001]:\n",
    "    for modelo in modelos.keys(): # Para cada modelo\n",
    "        for indice_otimizador in range(3): # Para cada otimizador\n",
    "            # Cria lista vazia para armazena a precisão de cada rede ao ser treinada na época Ni\n",
    "            precisões = [0 for i in range(N)]\n",
    "\n",
    "            for execução in range(N): # Para cada execução\n",
    "                report=\"\"\n",
    "                # Instancie um novo loader de treino e validação a cada execução, aleatorizando novamente os índices\n",
    "                loader_treino, loader_validação = CriarDataloaders(dataset=ds_massey,bagunçar=True,porcentagem_split=.2)\n",
    "\n",
    "                # Instancie um modelo da lista de modelos para ser treinado e validado\n",
    "                modelo_instanciado = modelos[modelo](36).to(dispositivo)\n",
    "\n",
    "                # Instancie nova função de custo (Entropia Cruzada) -> (guarda historico)\n",
    "                fun_custo = gp.get_fun_custo()\n",
    "\n",
    "                # Escolha uma nova taxa de aprendizagem (da lista cíclica de taxas)\n",
    "                    # Ciclo de taxas de aprendizado [ -> 0.5 -> 0.1 -> 0.05 -> 0.001] muda para o prox a cada execução\n",
    "                report+=\"Taxa de Aprendizado = \"+str(taxa_aprendizado)+', '\n",
    "\n",
    "                # Instancie um otimizador\n",
    "                    # Ciclo de otimizadores [ -> 'Gradiente Descendente' -> 'Adagrad' -> 'Adam' ]\n",
    "                otimizador = gp.get_otimizador(indice_otimizador)(modelo_instanciado.parameters(),lr=taxa_aprendizado)\n",
    "                report += \"Otimizador = \"+gp.get_otimizador(indice_otimizador,True)+', Número de Épocas = '+str(épocas)+', '\n",
    "\n",
    "                # Treine o modelo instanciado com os seus parâmetros (n epocas, otimizador, loader de treino)\n",
    "                modelo_instanciado,_,_ = treinar(loader_treino,modelo_instanciado,épocas,fun_custo,otimizador,dispositivo,modelo,gp.get_otimizador(indice_otimizador,True),execução)\n",
    "\n",
    "                ####### CÓDIGO PARA VALIDAÇÃO #######\n",
    "                precisão = validar(loader_validação,modelo_instanciado,dispositivo)\n",
    "                precisões[execução] = precisão\n",
    "                report += \"Precisão = \"+\"{:.2f}\".format(precisão)+\"%\"\n",
    "                # Armazena linha de report para modelo com otimizador\n",
    "                guardar_report(report=report,modelo=modelo,otimizador=gp.get_otimizador(indice_otimizador,True))\n",
    "\n",
    "            # Após as N execuções (preencheu a lista de médias para esta rede com este otimizador), armazene a precisão média e o desvio padrão\n",
    "            armazenar_media_desvio(lista_precisões=precisões,nome_modelo=modelo,nome_otimizador=gp.get_otimizador(indice_otimizador,True))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "naughty-fitness",
   "metadata": {},
   "source": [
    "- Resumo\n",
    "    - Cada Modelo tem **20 execuções** para cada tipo de otimizador\n",
    "    - Cada otimizador executa **N/4 vezes para cada taxa de aprendizagem**\n",
    "    - O Loader de dados de *Treino e Validação* tem os índices **reatribuídos e aleatorizados a cada execução** (mantendo 20% dos índices para validação)\n",
    "    - São efetuadas um total de (**<i>Número de Modelos</i> \\* N \\* *Número de Otimizadores* \\* Número de Taxas de Aprendizado**) Treinamentos de **X** épocas]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
